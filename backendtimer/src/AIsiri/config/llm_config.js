'use strict';

const OpenAI = require('openai');
const path = require('path');
const fs = require('fs');

class LLMConfig {
  constructor() {
    this.loadAPIKey();
    this.initializeClient();
  }

  loadAPIKey() {
    try {
      // è¯»å–APIå¯†é’¥æ–‡ä»¶
      const apiKeyPath = path.join(__dirname, '../../../doc/APIkey');
      const apiKeyContent = fs.readFileSync(apiKeyPath, 'utf8');
      const lines = apiKeyContent.trim().split('\n');
      
      this.apiKey = lines[0].trim(); // sk-6179141aaa3e43499173c37c078b4aaf
      this.model = lines[2].trim();  // qwen-plus
      
      console.log('âœ… APIé…ç½®åŠ è½½æˆåŠŸ');
      console.log(`ğŸ“ ä½¿ç”¨æ¨¡å‹: ${this.model}`);
    } catch (error) {
      console.error('âŒ æ— æ³•åŠ è½½APIå¯†é’¥:', error.message);
      throw error;
    }
  }

  initializeClient() {
    try {
      this.client = new OpenAI({
        apiKey: this.apiKey,
        baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"
      });
      console.log('âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ');
    } catch (error) {
      console.error('âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥:', error.message);
      throw error;
    }
  }

  async testConnection() {
    try {
      console.log('ğŸ”— æµ‹è¯•LLMè¿æ¥...');
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          { role: "system", content: "You are a helpful assistant." },
          { role: "user", content: "Hello, please respond with 'Connection successful!'" }
        ],
        max_tokens: 50
      });
      
      console.log('âœ… LLMè¿æ¥æµ‹è¯•æˆåŠŸ');
      console.log('ğŸ“¤ å“åº”:', response.choices[0].message.content);
      return true;
    } catch (error) {
      console.error('âŒ LLMè¿æ¥æµ‹è¯•å¤±è´¥:', error.message);
      return false;
    }
  }

  getClient() {
    return this.client;
  }

  getModel() {
    return this.model;
  }
}

module.exports = LLMConfig;